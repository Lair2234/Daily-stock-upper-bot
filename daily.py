import os
import requests
import csv
from io import StringIO
from datetime import datetime, timezone, timedelta
from bs4 import BeautifulSoup

# ==============================
# í…”ë ˆê·¸ë¨ ì„¤ì •
# ==============================
TOKEN = os.environ.get("TELEGRAM_TOKEN")
CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")

if not TOKEN or not CHAT_ID:
    raise Exception("í…”ë ˆê·¸ë¨ í™˜ê²½ë³€ìˆ˜ ì—†ìŒ")

# ==============================
# ì„¸ì…˜ ìƒì„±
# ==============================
session = requests.Session()
session.headers.update({
    "User-Agent": "Mozilla/5.0",
})

# ==============================
# 1ï¸âƒ£ OTP ìƒì„±
# ==============================
def generate_otp(today):
    otp_url = "https://data.krx.co.kr/comm/fileDn/GenerateOTP/generate.cmd"

    data = {
        "searchType": "1",
        "mktId": "ALL",
        "trdDd": today,
        "csvxls_isNo": "false",
        "name": "fileDown",
        "url": "dbms/MDC/STAT/standard/MDCSTAT03901"
    }

    res = session.post(
        otp_url,
        data=data,
        headers={
            "Referer": "https://data.krx.co.kr/contents/MDC/MDI/mdiLoader",
            "Origin": "https://data.krx.co.kr"
        }
    )

    return res.text.strip()


# ==============================
# 2ï¸âƒ£ KRX ë°ì´í„° ë‹¤ìš´ë¡œë“œ
# ==============================
def get_krx_data(today):
    otp = generate_otp(today)

    download_url = "https://data.krx.co.kr/comm/fileDn/download_csv/download.cmd"

    res = session.post(
        download_url,
        data={"code": otp},
        headers={
            "Referer": "https://data.krx.co.kr/contents/MDC/MDI/mdiLoader",
            "Origin": "https://data.krx.co.kr"
        }
    )

    if res.status_code != 200:
        raise Exception("KRX ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")

    if not res.content:
        raise Exception("KRX ì‘ë‹µì´ ë¹„ì–´ ìˆìŒ (ì•„ì§ ë°ì´í„° ìƒì„± ì•ˆ ë¨)")

    decoded = res.content.decode("euc-kr")

    f = StringIO(decoded)
    reader = csv.reader(f)
    rows = list(reader)

    if len(rows) == 0:
        raise Exception("CSV ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŒ")

    headers = rows[0]
    data_rows = rows[1:]

    return headers, data_rows


# ==============================
# 3ï¸âƒ£ ìƒí•œê°€ ì¢…ëª© í•„í„°
# ==============================
def find_column(headers, keyword):
    for i, col in enumerate(headers):
        if keyword in col:
            return i
    return -1


def get_upper_stocks():
    # í•œêµ­ì‹œê°„ ê¸°ì¤€ ë‹¹ì¼
    kst = timezone(timedelta(hours=9))
    today = datetime.now(kst).strftime("%Y%m%d")

    headers, rows = get_krx_data(today)

    print("ì»¬ëŸ¼ ëª©ë¡:", headers)

    name_idx = find_column(headers, "ì¢…ëª©ëª…")
    price_idx = find_column(headers, "ì¢…ê°€")
    change_idx = find_column(headers, "ë“±ë½ë¥ ")
    value_idx = find_column(headers, "ê±°ë˜ëŒ€ê¸ˆ")
    foreign_idx = find_column(headers, "ì™¸êµ­ì¸")
    inst_idx = find_column(headers, "ê¸°ê´€")

    stocks = []

    for row in rows:
        try:
            change_rate = row[change_idx].replace("%", "").strip()

            if float(change_rate) >= 29.9:
                stocks.append({
                    "name": row[name_idx],
                    "price": row[price_idx],
                    "value": row[value_idx],
                    "foreign": row[foreign_idx],
                    "institution": row[inst_idx]
                })
        except:
            continue

    return stocks


# ==============================
# 4ï¸âƒ£ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
# ==============================
def get_news(name):
    url = f"https://search.naver.com/search.naver?where=news&query={name}"
    res = session.get(url)

    soup = BeautifulSoup(res.text, "html.parser")
    titles = soup.select("a.news_tit")[:3]

    return [t.text.strip() for t in titles]


# ==============================
# 5ï¸âƒ£ ë©”ì‹œì§€ ìƒì„±
# ==============================
stocks = get_upper_stocks()
today_msg = datetime.now().strftime("%Y-%m-%d")

print("ìƒí•œê°€ ì¢…ëª© ìˆ˜:", len(stocks))

if not stocks:
    message = f"[{today_msg}] ì˜¤ëŠ˜ ìƒí•œê°€ ì¢…ëª© ì—†ìŒ"
else:
    message_lines = []

    for s in stocks:
        news_list = get_news(s["name"])

        block = (
            f"ğŸ“ˆ {s['name']} ({s['price']})\n"
            f"- ê±°ë˜ëŒ€ê¸ˆ: {s['value']}\n"
            f"- ì™¸ì¸ ìˆœë§¤ìˆ˜: {s['foreign']}\n"
            f"- ê¸°ê´€ ìˆœë§¤ìˆ˜: {s['institution']}\n"
        )

        if news_list:
            block += "\nìµœê·¼ ë‰´ìŠ¤:\n"
            for n in news_list:
                block += f"- {n}\n"

        message_lines.append(block)

    message = f"[{today_msg}] ì˜¤ëŠ˜ì˜ ìƒí•œê°€ ì¢…ëª©\n\n" + "\n\n".join(message_lines)


# ==============================
# 6ï¸âƒ£ í…”ë ˆê·¸ë¨ ì „ì†¡
# ==============================
telegram_url = f"https://api.telegram.org/bot{TOKEN}/sendMessage"

requests.post(
    telegram_url,
    data={
        "chat_id": CHAT_ID,
        "text": message
    }
)

print("ì „ì†¡ ì™„ë£Œ")
